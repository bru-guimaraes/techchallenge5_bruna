import time
import logging
import sys
import os
import json

from fastapi import FastAPI, HTTPException, Response, Request, UploadFile, File
from pythonjsonlogger import jsonlogger
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from pydantic import BaseModel
from typing import Literal, Dict, List
import joblib
import pandas as pd
import shap
from shap.utils._exceptions import InvalidModelError

from utils.paths import PATH_MODEL

# ‚Äî‚Äî‚Äî Logger JSON ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
logger = logging.getLogger("uvicorn.access")
handler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter(
    '%(asctime)s %(name)s %(levelname)s %(message)s'
)
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

# ‚Äî‚Äî‚Äî M√©tricas Prometheus ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
REQUEST_COUNT = Counter(
    'request_count', 'Total HTTP requests',
    ['method', 'endpoint', 'http_status']
)
REQUEST_LATENCY = Histogram(
    'request_latency_seconds', 'HTTP request latency',
    ['endpoint']
)
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

START_TIME = time.time()

app = FastAPI(
    title="Decision Recruitment API",
    description=(
        "API para:\n"
        " ‚Ä¢ Classifica√ß√£o bin√°ria de candidatos (match sim/n√£o)\n"
        " ‚Ä¢ Retorno de scores cont√≠nuos de compatibilidade\n"
        " ‚Ä¢ Explica√ß√µes de decis√£o via SHAP\n"
        " ‚Ä¢ Ajuste din√¢mico de threshold e upload de hist√≥rico"
    ),
    version="1.0.0"
)

# ‚Äî‚Äî‚Äî Carrega modelo, features e explainer ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
try:
    modelo = joblib.load(PATH_MODEL)
    features_path = os.path.join(os.path.dirname(PATH_MODEL), "features.json")
    with open(features_path, "r", encoding="utf-8") as f:
        feature_names = json.load(f)
    try:
        explainer = shap.TreeExplainer(modelo)
    except InvalidModelError:
        # fallback silencioso
        class DummyExplainer:
            def shap_values(self, X): return [ [0]*X.shape[1], [0]*X.shape[1] ]
        explainer = DummyExplainer()
except Exception as e:
    raise RuntimeError(f"Erro ao inicializar a aplica√ß√£o: {e}")
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

# ‚Äî‚Äî‚Äî Pydantic Models ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
class PredictRequest(BaseModel):
    area_atuacao: str
    nivel_ingles: Literal["baixo", "medio", "alto"]
    nivel_espanhol: Literal["baixo", "medio", "alto"]
    nivel_academico: Literal["medio", "superior", "pos", "mestrado", "doutorado"]

class PredictProbaResponse(BaseModel):
    prediction: int
    probability: float

class ExplainResponse(BaseModel):
    prediction: int
    probability: float
    explanation: Dict[str, float]

class FeedbackRequest(BaseModel):
    input: PredictRequest
    prediction: Literal[0, 1]
    actual: Literal[0, 1]

class BatchPredictRequest(BaseModel):
    inputs: List[PredictRequest]

class BatchPredictResponse(BaseModel):
    results: List[PredictProbaResponse]

class CompareRequest(BaseModel):
    cand_a: PredictRequest
    cand_b: PredictRequest

class CompareResponse(BaseModel):
    a: PredictProbaResponse
    b: PredictProbaResponse
    delta: Dict[str, float]

class ThresholdRequest(BaseModel):
    threshold: float
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

THRESHOLD = 0.5

# ‚Äî‚Äî‚Äî Middleware para logs + m√©tricas ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start = time.time()
    response = await call_next(request)
    latency = time.time() - start

    REQUEST_LATENCY.labels(request.url.path).observe(latency)
    REQUEST_COUNT.labels(request.method, request.url.path, response.status_code).inc()

    logger.info('', extra={
        "method": request.method,
        "path": request.url.path,
        "status": response.status_code,
        "latency": latency
    })
    return response
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

# ‚Äî‚Äî‚Äî GET Endpoints ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

@app.get("/", summary="P√°gina inicial",
         description="‚Ä¢ O que √©: Endpoint raiz.\n‚Ä¢ O que resolve: Verifica disponibilidade.\n‚Ä¢ Quando usar: Teste manual.")
def root():
    return {"mensagem": "API funcionando com sucesso üöÄ"}

@app.get("/health", summary="Health check b√°sico",
         description="‚Ä¢ O que √©: Health simples.\n‚Ä¢ O que resolve: Monitoramento b√°sico.\n‚Ä¢ Quando usar: Orquestradores.")
def health():
    return {"status": "ok"}

@app.get("/health_detailed", summary="Health check detalhado",
         description="‚Ä¢ O que √©: Uptime e vers√£o Python.\n‚Ä¢ O que resolve: Diagn√≥stico operacional.\n‚Ä¢ Quando usar: Infra SRE.")
def health_detailed():
    return {
        "status": "ok",
        "uptime_seconds": time.time() - START_TIME,
        "python_version": sys.version.split()[0],
    }

@app.get("/metrics", summary="M√©tricas Prometheus",
         description="‚Ä¢ O que √©: M√©tricas internas.\n‚Ä¢ O que resolve: Integra√ß√£o Prometheus.\n‚Ä¢ Quando usar: Dashboards.")
def metrics():
    data = generate_latest()
    return Response(data, media_type=CONTENT_TYPE_LATEST)

@app.get("/model_info", summary="Informa√ß√µes do modelo",
         description="‚Ä¢ O que √©: Metadados do modelo.\n‚Ä¢ O que resolve: Auditoria ML.\n‚Ä¢ Quando usar: Compliance.")
def model_info():
    return {
        "version": app.version,
        "trained_on": "2025-07-01",
        "validation_accuracy": 0.87
    }

@app.get("/features", summary="Lista de features",
         description="‚Ä¢ O que √©: Vari√°veis de entrada.\n‚Ä¢ O que resolve: Guia payload.\n‚Ä¢ Quando usar: Antes da predi√ß√£o.")
def features():
    return {"features": feature_names}

@app.get("/global_explain", summary="Import√¢ncia global de features",
         description="‚Ä¢ O que √©: Import√¢ncia m√©dia (SHAP).\n‚Ä¢ O que resolve: Perfil geral de candidatos.\n‚Ä¢ Quando usar: Entendimento global do modelo.")
def global_explain():
    try:
        importances = modelo.feature_importances_
        vals = importances.tolist()
    except AttributeError:
        # fallback para explainer
        sample = pd.DataFrame([dict.fromkeys(feature_names, 0)])
        vals = explainer.shap_values(sample)[1][0]
        vals = list(map(abs, vals))
    return {"global_importance": dict(zip(feature_names, vals))}

@app.get("/threshold", summary="Consultar threshold",
         description="‚Ä¢ O que √©: Mostra corte atual.\n‚Ä¢ O que resolve: Transpar√™ncia na sensibilidade.\n‚Ä¢ Quando usar: Revis√£o de estrat√©gia.")
def get_threshold():
    return {"threshold": THRESHOLD}

# ‚Äî‚Äî‚Äî POST Endpoints ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

@app.post("/threshold", summary="Atualizar threshold",
          description="‚Ä¢ O que √©: Atualiza corte dinamicamente.\n‚Ä¢ O que resolve: Ajuste sem redeploy.\n‚Ä¢ Quando usar: Teste A/B ou tuning.")
def set_threshold(req: ThresholdRequest):
    global THRESHOLD
    THRESHOLD = req.threshold
    return {"threshold": THRESHOLD}

@app.post("/predict", response_model=PredictProbaResponse,
          summary="Classifica√ß√£o sim/n√£o",
          description="‚Ä¢ O que √©: Predi√ß√£o bin√°ria.\n‚Ä¢ O que resolve: Filtragem de candidatos.\n‚Ä¢ Quando usar: Triagem autom√°tica.")
def predict(req: PredictRequest):
    df = pd.DataFrame([req.dict()]); df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(500, f"Erro na predi√ß√£o: {e}")
    pred = int(probs[0] >= THRESHOLD)
    return {"prediction": pred, "probability": float(probs[0])}

@app.post("/predict_proba", response_model=PredictProbaResponse,
          summary="Score de compatibilidade",
          description="‚Ä¢ O que √©: Probabilidade cont√≠nua.\n‚Ä¢ O que resolve: Ranking de candidatos.\n‚Ä¢ Quando usar: Ordena√ß√£o por confian√ßa.")
def predict_proba(req: PredictRequest):
    df = pd.DataFrame([req.dict()]); df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(500, f"Erro na predi√ß√£o: {e}")
    return {"prediction": int(probs[0] >= THRESHOLD), "probability": float(probs[0])}

@app.post("/batch_predict", response_model=BatchPredictResponse,
          summary="Predi√ß√£o em lote",
          description="‚Ä¢ O que √©: Lista de candidatos.\n‚Ä¢ O que resolve: Processamento em massa.\n‚Ä¢ Quando usar: Pipelines de dados.")
def batch_predict(req: BatchPredictRequest):
    df = pd.DataFrame([i.dict() for i in req.inputs]); df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(500, f"Erro na predi√ß√£o em lote: {e}")
    results = [
        PredictProbaResponse(prediction=int(p>=THRESHOLD), probability=float(p))
        for p in probs
    ]
    return {"results": results}

@app.post("/explain", response_model=ExplainResponse,
          summary="Explica√ß√£o de decis√£o",
          description="‚Ä¢ O que √©: Contribui√ß√£o de cada feature (SHAP).\n‚Ä¢ O que resolve: Transpar√™ncia.\n‚Ä¢ Quando usar: Auditoria de decis√µes.")
def explain(req: PredictRequest):
    df = pd.DataFrame([req.dict()]); df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(500, f"Erro na predi√ß√£o: {e}")
    pred = int(probs[0] >= THRESHOLD)
    shap_vals = explainer.shap_values(df_aligned)[1][0]
    explanation = dict(zip(feature_names, map(float, shap_vals)))
    return {"prediction": pred, "probability": float(probs[0]), "explanation": explanation}

@app.post("/compare", response_model=CompareResponse,
          summary="Comparar dois candidatos",
          description="‚Ä¢ O que √©: Diff de SHAP + predi√ß√µes.\n‚Ä¢ O que resolve: Escolha entre perfis.\n‚Ä¢ Quando usar: Tie-breaker em sele√ß√£o.")
def compare(req: CompareRequest):
    def single(r):
        df = pd.DataFrame([r.dict()]); df_enc = pd.get_dummies(df)
        df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
        prob = modelo.predict_proba(df_aligned)[:,1][0]
        pred = int(prob >= THRESHOLD)
        shap_v = explainer.shap_values(df_aligned)[1][0]
        return pred, prob, shap_v

    a_pred, a_prob, a_shap = single(req.cand_a)
    b_pred, b_prob, b_shap = single(req.cand_b)
    delta = dict(zip(feature_names, (b_shap - a_shap).tolist()))
    return {
        "a": {"prediction": a_pred, "probability": a_prob},
        "b": {"prediction": b_pred, "probability": b_prob},
        "delta": delta
    }

@app.post("/feedback", summary="Registrar feedback",
          description="‚Ä¢ O que √©: Log de predi√ß√£o vs real.\n‚Ä¢ O que resolve: Monitoramento cont√≠nuo.\n‚Ä¢ Quando usar: P√≥s-outcome.")
def feedback(fb: FeedbackRequest):
    record = fb.dict()
    log_path = os.path.join(os.path.dirname(PATH_MODEL), "feedback_log.jsonl")
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")
    return {"status": "ok"}

@app.post("/historical_data", summary="Upload hist√≥rico",
          description="‚Ä¢ O que √©: Recebe CSV de entrevistas.\n‚Ä¢ O que resolve: An√°lise retroativa.\n‚Ä¢ Quando usar: Importa√ß√£o em massa.")
async def upload_historical(file: UploadFile = File(...)):
    os.makedirs("data", exist_ok=True)
    path = os.path.join("data", "historical_data.csv")
    with open(path, "wb") as f:
        f.write(await file.read())
    return {"status": "saved", "path": path}
