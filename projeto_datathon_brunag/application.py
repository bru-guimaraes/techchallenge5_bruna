import time
import logging
from fastapi import FastAPI, HTTPException, Response, Request
from pythonjsonlogger import jsonlogger
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from pydantic import BaseModel
from typing import Literal, Dict
import joblib
import json
import pandas as pd
import os
import shap

from utils.paths import PATH_MODEL

# â€”â€”â€” Logger JSON â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
logger = logging.getLogger("uvicorn.access")
handler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter('%(asctime)s %(name)s %(levelname)s %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” MÃ©tricas Prometheus â€”â€”â€”â€”â€”â€”â€”â€”â€”
REQUEST_COUNT = Counter(
    'request_count', 'Total HTTP requests',
    ['method', 'endpoint', 'http_status']
)
REQUEST_LATENCY = Histogram(
    'request_latency_seconds', 'HTTP request latency',
    ['endpoint']
)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

app = FastAPI(
    title="Decision Recruitment API",
    description="API para prediÃ§Ã£o de compatibilidade de candidatos, explicaÃ§Ã£o via SHAP e envio de feedback.",
    version="1.0.0"
)

# â€”â€”â€” Carrega modelo, features e explainer â€”â€”â€”
try:
    modelo = joblib.load(PATH_MODEL)
    features_path = os.path.join(os.path.dirname(PATH_MODEL), "features.json")
    with open(features_path, "r") as f:
        feature_names = json.load(f)
    explainer = shap.TreeExplainer(modelo)
except Exception as e:
    raise RuntimeError(f"Erro ao inicializar a aplicaÃ§Ã£o: {e}")
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Pydantic Models â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
class PredictRequest(BaseModel):
    area_atuacao: str
    nivel_ingles: Literal["baixo", "medio", "alto"]
    nivel_espanhol: Literal["baixo", "medio", "alto"]
    nivel_academico: Literal["medio", "superior", "pos", "mestrado", "doutorado"]

class PredictProbaResponse(BaseModel):
    prediction: int
    probability: float

class ExplainResponse(BaseModel):
    prediction: int
    probability: float
    explanation: Dict[str, float]

class FeedbackRequest(BaseModel):
    input: PredictRequest
    prediction: Literal[0, 1]
    actual: Literal[0, 1]
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Middleware para logs + mÃ©tricas â€”â€”â€”
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start = time.time()
    response = await call_next(request)
    latency = time.time() - start

    REQUEST_LATENCY.labels(request.url.path).observe(latency)
    REQUEST_COUNT.labels(request.method, request.url.path, response.status_code).inc()

    logger.info('', extra={
        "method": request.method,
        "path": request.url.path,
        "status": response.status_code,
        "latency": latency
    })
    return response
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Endpoint de mÃ©tricas Prometheus â€”â€”â€”
@app.get(
    "/metrics",
    summary="MÃ©tricas Prometheus",
    description="Retorna mÃ©tricas em formato Prometheus para monitoramento."
)
def metrics():
    data = generate_latest()
    return Response(data, media_type=CONTENT_TYPE_LATEST)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Health check â€”â€”â€”â€”â€”â€”â€”â€”
@app.get(
    "/health",
    summary="VerificaÃ§Ã£o de saÃºde",
    description="Confirma se a API estÃ¡ operando corretamente."
)
def health():
    return {"status": "ok"}

@app.get(
    "/",
    summary="PÃ¡gina inicial",
    description="Mensagem de boas-vindas e status da API."
)
def root():
    return {"mensagem": "API funcionando com sucesso ðŸš€"}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 1) /predict â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/predict",
    response_model=PredictProbaResponse,
    summary="DecisÃ£o de contrataÃ§Ã£o (sim/nÃ£o)",
    description=(
        "Recebe dados do candidato e devolve:\n"
        "  â€¢ `prediction`: 1 se a probabilidade â‰¥ 50% (caso contrÃ¡rio 0)\n"
        "  â€¢ `probability`: valor de 0.0 a 1.0 usado para tomar essa decisÃ£o"
    )
)
def predict(req: PredictRequest):
    df = pd.DataFrame([req.dict()])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o: {e}")
    pred = int(probs[0] >= 0.5)
    return {"prediction": pred, "probability": float(probs[0])}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 2) /predict_proba â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/predict_proba",
    response_model=PredictProbaResponse,
    summary="Score de compatibilidade (0â€“1)",
    description=(
        "Recebe dados do candidato e devolve apenas o valor de probabilidade "
        "(raw score de 0.0 a 1.0), sem converter para sim/nÃ£o.\n\n"
        "Use este endpoint quando quiser:\n"
        "  â€¢ Ordenar candidatos pelo score\n"
        "  â€¢ Analisar graus de confianÃ§a em vez de decisÃ£o binÃ¡ria"
    )
)
def predict_proba(req: PredictRequest):
    df = pd.DataFrame([req.dict()])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o: {e}")
    pred = int(probs[0] >= 0.5)
    return {"prediction": pred, "probability": float(probs[0])}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 3) /explain â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/explain",
    response_model=ExplainResponse,
    summary="ExplicaÃ§Ã£o via SHAP",
    description="Gera explicaÃ§Ã£o das contribuiÃ§Ãµes de cada caracterÃ­stica usando SHAP."
)
def explain(req: PredictRequest):
    df = pd.DataFrame([req.dict()])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o: {e}")
    pred = int(probs[0] >= 0.5)

    shap_vals = explainer.shap_values(df_aligned)[1][0]
    explanation = {feat: float(val) for feat, val in zip(feature_names, shap_vals)}
    return {"prediction": pred, "probability": float(probs[0]), "explanation": explanation}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 4) /feedback â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/feedback",
    summary="Registrar feedback",
    description="Registra a diferenÃ§a entre prediÃ§Ã£o e resultado real para acompanhamento e retraining."
)
def feedback(fb: FeedbackRequest):
    record = fb.dict()
    log_path = os.path.join(os.path.dirname(PATH_MODEL), "feedback_log.jsonl")
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")
    return {"status": "ok"}
