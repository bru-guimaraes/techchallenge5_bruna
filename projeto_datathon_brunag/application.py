import time
import logging
from fastapi import FastAPI, HTTPException, Response, Request
from pythonjsonlogger import jsonlogger
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from pydantic import BaseModel
from typing import Literal, Dict
import joblib
import json
import pandas as pd
import os
import shap

from utils.paths import PATH_MODEL

# â€”â€”â€” Logger JSON â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
logger = logging.getLogger("uvicorn.access")
handler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter('%(asctime)s %(name)s %(levelname)s %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” MÃ©tricas Prometheus â€”â€”â€”â€”â€”â€”â€”â€”â€”
REQUEST_COUNT = Counter(
    'request_count', 'Total HTTP requests',
    ['method', 'endpoint', 'http_status']
)
REQUEST_LATENCY = Histogram(
    'request_latency_seconds', 'HTTP request latency',
    ['endpoint']
)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

app = FastAPI(
    title="Decision Recruitment API",
    description="API para prediÃ§Ã£o de match de candidatos, explicaÃ§Ã£o via SHAP e envio de feedback.",
    version="1.0.0"
)

# â€”â€”â€” 1. Carregamento do modelo, features e explainer â€”â€”â€”
try:
    modelo = joblib.load(PATH_MODEL)
    features_path = os.path.join(os.path.dirname(PATH_MODEL), "features.json")
    with open(features_path, "r") as f:
        feature_names = json.load(f)
    # SHAP explainer
    explainer = shap.TreeExplainer(modelo)
except Exception as e:
    raise RuntimeError(f"Erro ao inicializar a aplicaÃ§Ã£o: {e}")
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Pydantic Models â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
class EntradaExemplo(BaseModel):
    nome: str
    idade: int

class PredictRequest(BaseModel):
    area_atuacao: str
    nivel_ingles: Literal["baixo", "medio", "alto"]
    nivel_espanhol: Literal["baixo", "medio", "alto"]
    nivel_academico: Literal["medio", "superior", "pos", "mestrado", "doutorado"]

class PredictProbaResponse(BaseModel):
    prediction: int
    probability: float

class ExplainResponse(BaseModel):
    prediction: int
    probability: float
    explanation: Dict[str, float]

class FeedbackRequest(BaseModel):
    input: PredictRequest
    prediction: Literal[0, 1]
    actual: Literal[0, 1]
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Middleware para logs + mÃ©tricas â€”â€”â€”
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start = time.time()
    response = await call_next(request)
    latency = time.time() - start

    # Prometheus
    REQUEST_LATENCY.labels(request.url.path).observe(latency)
    REQUEST_COUNT.labels(request.method, request.url.path, response.status_code).inc()

    # JSON log
    logger.info('', extra={
        "method": request.method,
        "path": request.url.path,
        "status": response.status_code,
        "latency": latency
    })

    return response
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Endpoint de mÃ©tricas Prometheus â€”â€”â€”
@app.get(
    "/metrics",
    summary="MÃ©tricas Prometheus",
    description="Retorna mÃ©tricas para monitoramento (Prometheus format)."
)
def metrics():
    data = generate_latest()
    return Response(data, media_type=CONTENT_TYPE_LATEST)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Health check / Root â€”â€”â€”â€”â€”â€”â€”â€”
@app.get(
    "/health",
    summary="Health Check",
    description="Verifica se a API estÃ¡ operante."
)
def health():
    return {"status": "ok"}

@app.get(
    "/",
    summary="Root",
    description="Mensagem de boas-vindas e status da API."
)
def root():
    return {"mensagem": "API funcionando com sucesso ğŸš€"}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Exemplo de endpoint â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/exemplo",
    summary="Exemplo",
    description="Recebe nome e idade e retorna saudaÃ§Ã£o personalizada."
)
def exemplo_endpoint(dados: EntradaExemplo):
    return {"mensagem": f"OlÃ¡, {dados.nome}! VocÃª tem {dados.idade} anos."}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 1) /predict â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/predict",
    response_model=PredictProbaResponse,
    summary="PrediÃ§Ã£o",
    description="Recebe dados do candidato e retorna classe predita e probabilidade de contrataÃ§Ã£o."
)
def predict(req: PredictRequest):
    df = pd.DataFrame([req.dict()])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o: {e}")
    pred = int(probs[0] >= 0.5)
    return {"prediction": pred, "probability": float(probs[0])}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 2) /predict_proba â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/predict_proba",
    response_model=PredictProbaResponse,
    summary="Probabilidade",
    description="Retorna apenas a classe e a probabilidade sem threshold."
)
def predict_proba(req: PredictRequest):
    df = pd.DataFrame([req.dict()])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o: {e}")
    pred = int(probs[0] >= 0.5)
    return {"prediction": pred, "probability": float(probs[0])}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 3) /explain â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/explain",
    response_model=ExplainResponse,
    summary="ExplicaÃ§Ã£o SHAP",
    description="Gera explicaÃ§Ã£o de feature contributions usando SHAP."
)
def explain(req: PredictRequest):
    df = pd.DataFrame([req.dict()])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o: {e}")
    pred = int(probs[0] >= 0.5)

    # SHAP values para classe â€œ1â€
    shap_vals = explainer.shap_values(df_aligned)[1][0]
    explanation = {feat: float(val) for feat, val in zip(feature_names, shap_vals)}

    return {"prediction": pred, "probability": float(probs[0]), "explanation": explanation}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 4) /feedback â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/feedback",
    summary="Feedback",
    description="Registra feedback entre prediÃ§Ã£o e valor real para monitoramento e re-treino."
)
def feedback(fb: FeedbackRequest):
    record = fb.dict()
    log_path = os.path.join(os.path.dirname(PATH_MODEL), "feedback_log.jsonl")
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    # append como JSON lines
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")
    return {"status": "ok"}
