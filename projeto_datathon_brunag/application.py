import time
import logging
import sys
import os
import json

from fastapi import FastAPI, HTTPException, Response, Request, UploadFile, File
from pythonjsonlogger import jsonlogger
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from pydantic import BaseModel
from typing import Literal, Dict, List
import joblib
import pandas as pd
import shap

from utils.paths import PATH_MODEL

# â€”â€”â€” Logger JSON â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
logger = logging.getLogger("uvicorn.access")
handler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter(
    '%(asctime)s %(name)s %(levelname)s %(message)s'
)
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” MÃ©tricas Prometheus â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
REQUEST_COUNT = Counter(
    'request_count', 'Total HTTP requests',
    ['method', 'endpoint', 'http_status']
)
REQUEST_LATENCY = Histogram(
    'request_latency_seconds', 'HTTP request latency',
    ['endpoint']
)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

START_TIME = time.time()

app = FastAPI(
    title="Decision Recruitment API",
    description=(
        "API para:\n"
        " â€¢ ClassificaÃ§Ã£o binÃ¡ria de candidatos (match sim/nÃ£o)\n"
        " â€¢ Retorno de scores contÃ­nuos de compatibilidade\n"
        " â€¢ ExplicaÃ§Ãµes de decisÃ£o via SHAP\n"
        " â€¢ Ajuste dinÃ¢mico de threshold e upload de histÃ³rico"
    ),
    version="1.0.0"
)

# â€”â€”â€” Carrega modelo, features e explainer â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
try:
    modelo = joblib.load(PATH_MODEL)
    features_path = os.path.join(os.path.dirname(PATH_MODEL), "features.json")
    with open(features_path, "r") as f:
        feature_names = json.load(f)
    explainer = shap.TreeExplainer(modelo)
except Exception as e:
    raise RuntimeError(f"Erro ao inicializar a aplicaÃ§Ã£o: {e}")
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” Pydantic Models â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
class PredictRequest(BaseModel):
    area_atuacao: str
    nivel_ingles: Literal["baixo", "medio", "alto"]
    nivel_espanhol: Literal["baixo", "medio", "alto"]
    nivel_academico: Literal["medio", "superior", "pos", "mestrado", "doutorado"]

class PredictProbaResponse(BaseModel):
    prediction: int
    probability: float

class ExplainResponse(BaseModel):
    prediction: int
    probability: float
    explanation: Dict[str, float]

class FeedbackRequest(BaseModel):
    input: PredictRequest
    prediction: Literal[0, 1]
    actual: Literal[0, 1]

class BatchPredictRequest(BaseModel):
    inputs: List[PredictRequest]

class BatchPredictResponse(BaseModel):
    results: List[PredictProbaResponse]

class CompareRequest(BaseModel):
    cand_a: PredictRequest
    cand_b: PredictRequest

class CompareResponse(BaseModel):
    a: PredictProbaResponse
    b: PredictProbaResponse
    delta: Dict[str, float]

class ThresholdRequest(BaseModel):
    threshold: float
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

THRESHOLD = 0.5

# â€”â€”â€” Middleware para logs + mÃ©tricas â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start = time.time()
    response = await call_next(request)
    latency = time.time() - start

    REQUEST_LATENCY.labels(request.url.path).observe(latency)
    REQUEST_COUNT.labels(request.method, request.url.path, response.status_code).inc()

    logger.info('', extra={
        "method": request.method,
        "path": request.url.path,
        "status": response.status_code,
        "latency": latency
    })
    return response
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 0) Root e health â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.get(
    "/",
    summary="PÃ¡gina inicial",
    description=(
        "O que Ã©: Endpoint raiz que confirma que a API estÃ¡ pronta.\n"
        "O que resolve: Verifica rapidamente a disponibilidade.\n"
        "Quando usar: Teste manual ou link na documentaÃ§Ã£o."
    )
)
def root():
    return {"mensagem": "API funcionando com sucesso ðŸš€"}

@app.get(
    "/health",
    summary="VerificaÃ§Ã£o de saÃºde bÃ¡sica",
    description=(
        "O que Ã©: Retorna status simples de operaÃ§Ã£o.\n"
        "O que resolve: Permite monitorar via checks de health.\n"
        "Quando usar: Orquestradores (K8s, ELB) verificam este endpoint."
    )
)
def health():
    return {"status": "ok"}

@app.get(
    "/health_detailed",
    summary="VerificaÃ§Ã£o de saÃºde detalhada",
    description=(
        "O que Ã©: Informe de uptime e versÃ£o do Python.\n"
        "O que resolve: Ajuda SREs a monitorar e debugar ambiente.\n"
        "Quando usar: DiagnÃ³stico avanÃ§ado e dashboards de operaÃ§Ãµes."
    )
)
def health_detailed():
    return {
        "status": "ok",
        "uptime_seconds": time.time() - START_TIME,
        "python_version": sys.version.split()[0],
    }
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 1) /metrics â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.get(
    "/metrics",
    summary="MÃ©tricas Prometheus",
    description=(
        "O que Ã©: MÃ©tricas internas em formato Prometheus.\n"
        "O que resolve: IntegraÃ§Ã£o com Prometheus/Grafana.\n"
        "Quando usar: Para coletar estatÃ­sticas de uso e performance."
    )
)
def metrics():
    data = generate_latest()
    return Response(data, media_type=CONTENT_TYPE_LATEST)
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 2) /model_info â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.get(
    "/model_info",
    summary="InformaÃ§Ãµes do modelo",
    description=(
        "O que Ã©: Metadados estÃ¡ticos do modelo (versÃ£o, data, acurÃ¡cia).\n"
        "O que resolve: Documenta o artefato em produÃ§Ã£o.\n"
        "Quando usar: Auditoria e compliance de ML ops."
    )
)
def model_info():
    return {
        "version": app.version,
        "trained_on": "2025-07-01",
        "validation_accuracy": 0.87
    }
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 3) /features â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.get(
    "/features",
    summary="Lista de features",
    description=(
        "O que Ã©: Exibe as variÃ¡veis de entrada esperadas.\n"
        "O que resolve: Ajuda integradores a construir payload correto.\n"
        "Quando usar: Antes de enviar dados para prediÃ§Ã£o."
    )
)
def features():
    return {"features": feature_names}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 4) /predict â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/predict",
    response_model=PredictProbaResponse,
    summary="DecisÃ£o de contrataÃ§Ã£o (sim/nÃ£o)",
    description=(
        "O que Ã©: Classifica candidato como 1 (match) ou 0 (no match).\n"
        "O que resolve: Filtra rapidamente candidatos para seleÃ§Ã£o.\n"
        "Quando usar: Implementar regras automÃ¡ticas de triagem."
    )
)
def predict(req: PredictRequest):
    df = pd.DataFrame([req.dict()])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o: {e}")
    pred = int(probs[0] >= THRESHOLD)
    return {"prediction": pred, "probability": float(probs[0])}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 5) /predict_proba â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/predict_proba",
    response_model=PredictProbaResponse,
    summary="Score de compatibilidade (0â€“1)",
    description=(
        "O que Ã©: Retorna probabilidade bruta de match.\n"
        "O que resolve: Permite classificar por ranking de confianÃ§a.\n"
        "Quando usar: AnÃ¡lise de candidatos em ordem decrescente de score."
    )
)
def predict_proba(req: PredictRequest):
    df = pd.DataFrame([req.dict()])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o: {e}")
    return {"prediction": int(probs[0] >= THRESHOLD), "probability": float(probs[0])}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 6) /batch_predict â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/batch_predict",
    response_model=BatchPredictResponse,
    summary="PrediÃ§Ã£o em lote",
    description=(
        "O que Ã©: Recebe lista de candidatos e devolve prediÃ§Ãµes em massa.\n"
        "O que resolve: Processa mÃºltiplos registros de forma eficiente.\n"
        "Quando usar: ImportaÃ§Ã£o em lote de planilhas ou pipelines de dados."
    )
)
def batch_predict(req: BatchPredictRequest):
    df = pd.DataFrame([i.dict() for i in req.inputs])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o em lote: {e}")
    results = [
        PredictProbaResponse(prediction=int(p >= THRESHOLD), probability=float(p))
        for p in probs
    ]
    return {"results": results}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 7) /explain â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/explain",
    response_model=ExplainResponse,
    summary="ExplicaÃ§Ã£o de decisÃ£o via SHAP",
    description=(
        "O que Ã©: Detalha contribuiÃ§Ã£o de cada feature para o resultado.\n"
        "O que resolve: TransparÃªncia e confianÃ§a no critÃ©rio de seleÃ§Ã£o.\n"
        "Quando usar: Auditoria de decisÃµes ou feedback aos gestores."
    )
)
def explain(req: PredictRequest):
    df = pd.DataFrame([req.dict()])
    df_enc = pd.get_dummies(df)
    df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(df_aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na prediÃ§Ã£o: {e}")
    pred = int(probs[0] >= THRESHOLD)
    shap_vals = explainer.shap_values(df_aligned)[1][0]
    explanation = {feat: float(val) for feat, val in zip(feature_names, shap_vals)}
    return {"prediction": pred, "probability": float(probs[0]), "explanation": explanation}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 8) /global_explain â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.get(
    "/global_explain",
    summary="ImportÃ¢ncia global de features",
    description=(
        "O que Ã©: Exibe importÃ¢ncia mÃ©dia de cada feature.\n"
        "O que resolve: Identifica atributos mais relevantes do modelo.\n"
        "Quando usar: Para entender perfil ideal de candidato a nÃ­vel geral."
    )
)
def global_explain():
    try:
        importances = modelo.feature_importances_
        return {"global_importance": dict(zip(feature_names, importances.tolist()))}
    except AttributeError:
        sample = pd.DataFrame([dict.fromkeys(feature_names, 0)])
        vals = explainer.shap_values(sample)[1][0]
        return {"global_importance": dict(zip(feature_names, map(abs, vals)))}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 9) /compare â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/compare",
    response_model=CompareResponse,
    summary="Comparar dois candidatos",
    description=(
        "O que Ã©: Compara prediÃ§Ãµes, scores e diferenÃ§as SHAP.\n"
        "O que resolve: Ajuda a escolher entre duas opÃ§Ãµes de perfil.\n"
        "Quando usar: Entrevista comparativa ou tie-breaker de seleÃ§Ã£o."
    )
)
def compare(req: CompareRequest):
    def single(r):
        df = pd.DataFrame([r.dict()])
        df_enc = pd.get_dummies(df)
        df_aligned = df_enc.reindex(columns=feature_names, fill_value=0)
        prob = modelo.predict_proba(df_aligned)[:, 1][0]
        pred = int(prob >= THRESHOLD)
        shap_v = explainer.shap_values(df_aligned)[1][0]
        return pred, prob, dict(zip(feature_names, shap_v))

    a_pred, a_prob, a_shap = single(req.cand_a)
    b_pred, b_prob, b_shap = single(req.cand_b)
    delta = {f: b_shap[f] - a_shap[f] for f in feature_names}
    return {
        "a": {"prediction": a_pred, "probability": a_prob},
        "b": {"prediction": b_pred, "probability": b_prob},
        "delta": delta
    }
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 10) /threshold â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.get(
    "/threshold",
    summary="Consultar threshold atual",
    description=(
        "O que Ã©: Exibe corte usado para decidir sim/nÃ£o.\n"
        "O que resolve: TransparÃªncia na sensibilidade do filtro.\n"
        "Quando usar: Antes de ajustar ou revisar polÃ­tica de contrataÃ§Ã£o."
    )
)
def get_threshold():
    return {"threshold": THRESHOLD}

@app.post(
    "/threshold",
    summary="Atualizar threshold de decisÃ£o",
    description=(
        "O que Ã©: Modifica o valor de corte sem redeploy.\n"
        "O que resolve: Ajusta sensibilidade (mais rigoroso ou mais flexÃ­vel).\n"
        "Quando usar: Testes A/B ou mudanÃ§as de estratÃ©gia de seleÃ§Ã£o."
    )
)
def set_threshold(req: ThresholdRequest):
    global THRESHOLD
    THRESHOLD = req.threshold
    return {"threshold": THRESHOLD}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 11) /feedback â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/feedback",
    summary="Registrar feedback",
    description=(
        "O que Ã©: Grava prediÃ§Ã£o vs resultado real para monitoring.\n"
        "O que resolve: Permite avaliar e melhorar performance ao longo do tempo.\n"
        "Quando usar: Sempre que tiver o outcome definitivo do candidato."
    )
)
def feedback(fb: FeedbackRequest):
    record = fb.dict()
    log_path = os.path.join(os.path.dirname(PATH_MODEL), "feedback_log.jsonl")
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")
    return {"status": "ok"}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”

# â€”â€”â€” 12) /historical_data â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
@app.post(
    "/historical_data",
    summary="Upload de dados histÃ³ricos",
    description=(
        "O que Ã©: Recebe CSV com histÃ³rico de entrevistas e outcomes.\n"
        "O que resolve: Facilita anÃ¡lise retroativa e novos treinamentos.\n"
        "Quando usar: ImportaÃ§Ã£o em massa de dados jÃ¡ consolidados."
    )
)
async def upload_historical(file: UploadFile = File(...)):
    os.makedirs("data", exist_ok=True)
    path = os.path.join("data", "historical_data.csv")
    with open(path, "wb") as f:
        f.write(await file.read())
    return {"status": "saved", "path": path}
# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”
