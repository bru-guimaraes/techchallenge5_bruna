import time
import logging
import sys
import os
import json

from fastapi import FastAPI, HTTPException, Response, Request, UploadFile, File
from pythonjsonlogger import jsonlogger
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
from pydantic import BaseModel
from typing import Literal, Dict, List
import joblib
import pandas as pd
import shap

from utils.paths import PATH_MODEL

# ‚Äî‚Äî‚Äî Logger JSON ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
logger = logging.getLogger("uvicorn.access")
handler = logging.StreamHandler()
formatter = jsonlogger.JsonFormatter(
    '%(asctime)s %(name)s %(levelname)s %(message)s'
)
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

# ‚Äî‚Äî‚Äî M√©tricas Prometheus ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
REQUEST_COUNT = Counter(
    'request_count', 'Total HTTP requests',
    ['method', 'endpoint', 'http_status']
)
REQUEST_LATENCY = Histogram(
    'request_latency_seconds', 'HTTP request latency',
    ['endpoint']
)
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

START_TIME = time.time()

app = FastAPI(
    title="Decision Recruitment API",
    description=(
        "API para:\n"
        " ‚Ä¢ Classifica√ß√£o bin√°ria de candidatos (match sim/n√£o)\n"
        " ‚Ä¢ Retorno de scores cont√≠nuos de compatibilidade\n"
        " ‚Ä¢ Explica√ß√µes de decis√£o via SHAP\n"
        " ‚Ä¢ Ajuste din√¢mico de threshold e upload de hist√≥rico"
    ),
    version="1.0.0"
)

# ‚Äî‚Äî‚Äî Carrega modelo, features e explainer ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
try:
    modelo = joblib.load(PATH_MODEL)
    features_path = os.path.join(os.path.dirname(PATH_MODEL), "features.json")
    with open(features_path, "r", encoding="utf-8") as f:
        feature_names = json.load(f)
    explainer = shap.TreeExplainer(modelo)
except Exception as e:
    raise RuntimeError(f"Erro ao inicializar a aplica√ß√£o: {e}")
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

# ‚Äî‚Äî‚Äî Pydantic Models ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
class PredictRequest(BaseModel):
    area_atuacao: str
    nivel_ingles: Literal["baixo", "medio", "alto"]
    nivel_espanhol: Literal["baixo", "medio", "alto"]
    nivel_academico: Literal["medio", "superior", "pos", "mestrado", "doutorado"]

class PredictProbaResponse(BaseModel):
    prediction: int
    probability: float

class ExplainResponse(BaseModel):
    prediction: int
    probability: float
    explanation: Dict[str, float]

class FeedbackRequest(BaseModel):
    input: PredictRequest
    prediction: Literal[0, 1]
    actual: Literal[0, 1]

class BatchPredictRequest(BaseModel):
    inputs: List[PredictRequest]

class BatchPredictResponse(BaseModel):
    results: List[PredictProbaResponse]

class CompareRequest(BaseModel):
    cand_a: PredictRequest
    cand_b: PredictRequest

class CompareResponse(BaseModel):
    a: PredictProbaResponse
    b: PredictProbaResponse
    delta: Dict[str, float]

class ThresholdRequest(BaseModel):
    threshold: float
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

THRESHOLD = 0.5

# ‚Äî‚Äî‚Äî Middleware para logs + m√©tricas ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start = time.time()
    response = await call_next(request)
    latency = time.time() - start

    REQUEST_LATENCY.labels(request.url.path).observe(latency)
    REQUEST_COUNT.labels(request.method, request.url.path, response.status_code).inc()

    logger.info('', extra={
        "method": request.method,
        "path": request.url.path,
        "status": response.status_code,
        "latency": latency
    })
    return response
# ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

# ‚Äî‚Äî‚Äî GET ENDPOINTS (lista primeiro) ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

@app.get("/", summary="P√°gina inicial",
         description="‚Ä¢ O que √©: Endpoint raiz para checar disponibilidade.\n"
                     "‚Ä¢ Quando usar: Teste manual ou link na documenta√ß√£o.\n"
                     "‚Ä¢ Que dor resolve: Confirma se a API est√° online.")
def root():
    return {"mensagem": "API funcionando com sucesso üöÄ"}

@app.get("/health", summary="Verifica√ß√£o de sa√∫de b√°sica",
         description="‚Ä¢ O que √©: Retorna status simples.\n"
                     "‚Ä¢ Quando usar: Health checks em orquestradores.\n"
                     "‚Ä¢ Que dor resolve: Monitoramento b√°sico de uptime.")
def health():
    return {"status": "ok"}

@app.get("/health_detailed", summary="Verifica√ß√£o de sa√∫de detalhada",
         description="‚Ä¢ O que √©: Uptime e vers√£o Python.\n"
                     "‚Ä¢ Quando usar: Diagn√≥stico aprofundado.\n"
                     "‚Ä¢ Que dor resolve: Debug e observabilidade de ambiente.")
def health_detailed():
    return {
        "status": "ok",
        "uptime_seconds": time.time() - START_TIME,
        "python_version": sys.version.split()[0],
    }

@app.get("/metrics", summary="M√©tricas Prometheus",
         description="‚Ä¢ O que √©: M√©tricas internas em formato Prometheus.\n"
                     "‚Ä¢ Quando usar: Integra√ß√£o com Prometheus/Grafana.\n"
                     "‚Ä¢ Que dor resolve: Coleta de estat√≠sticas de uso e performance.")
def metrics():
    data = generate_latest()
    return Response(data, media_type=CONTENT_TYPE_LATEST)

@app.get("/model_info", summary="Informa√ß√µes do modelo",
         description="‚Ä¢ O que √©: Metadados do artefato ML.\n"
                     "‚Ä¢ Quando usar: Auditoria e compliance.\n"
                     "‚Ä¢ Que dor resolve: Documenta√ß√£o de vers√£o e acur√°cia.")
def model_info():
    return {
        "version": app.version,
        "trained_on": "2025-07-01",
        "validation_accuracy": 0.87
    }

@app.get("/features", summary="Lista de features",
         description="‚Ä¢ O que √©: Vari√°veis de entrada esperadas.\n"
                     "‚Ä¢ Quando usar: Constru√ß√£o de payload de predi√ß√£o.\n"
                     "‚Ä¢ Que dor resolve: Minimiza erros de contrato de API.")
def features():
    return {"features": feature_names}

@app.get("/global_explain", summary="Import√¢ncia global de features",
         description="‚Ä¢ O que √©: Import√¢ncia m√©dia de cada feature.\n"
                     "‚Ä¢ Quando usar: Entender perfil ideal de candidato.\n"
                     "‚Ä¢ Que dor resolve: Transpar√™ncia global do modelo.")
def global_explain():
    try:
        importances = modelo.feature_importances_
        return {"global_importance": dict(zip(feature_names, importances.tolist()))}
    except AttributeError:
        sample = pd.DataFrame([dict.fromkeys(feature_names, 0)])
        vals = explainer.shap_values(sample)[1][0]
        return {"global_importance": dict(zip(feature_names, map(abs, vals)))}

@app.get("/threshold", summary="Consultar threshold atual",
         description="‚Ä¢ O que √©: Valor de corte para decis√£o match.\n"
                     "‚Ä¢ Quando usar: Antes de ajustar sensibilidade.\n"
                     "‚Ä¢ Que dor resolve: Transpar√™ncia no filtro de candidatos.")
def get_threshold():
    return {"threshold": THRESHOLD}

# ‚Äî‚Äî‚Äî POST ENDPOINTS ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî

@app.post("/predict", response_model=PredictProbaResponse,
          summary="Decis√£o de contrata√ß√£o (sim/n√£o)",
          description="‚Ä¢ O que √©: Classifica candidato como match (1) ou no-match (0).\n"
                      "‚Ä¢ Quando usar: Triagem autom√°tica inicial.\n"
                      "‚Ä¢ Que dor resolve: Agiliza filtragem de grandes volumes.")
def predict(req: PredictRequest):
    df_enc = pd.get_dummies(pd.DataFrame([req.dict()]))
    aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na predi√ß√£o: {e}")
    pred = int(probs[0] >= THRESHOLD)
    return {"prediction": pred, "probability": float(probs[0])}

@app.post("/predict_proba", response_model=PredictProbaResponse,
          summary="Score de compatibilidade (0‚Äì1)",
          description="‚Ä¢ O que √©: Probabilidade bruta de match.\n"
                      "‚Ä¢ Quando usar: Ranking por confian√ßa.\n"
                      "‚Ä¢ Que dor resolve: Prioriza√ß√£o de candidatos por score.")
def predict_proba(req: PredictRequest):
    df_enc = pd.get_dummies(pd.DataFrame([req.dict()]))
    aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na predi√ß√£o: {e}")
    return {"prediction": int(probs[0] >= THRESHOLD), "probability": float(probs[0])}

@app.post("/batch_predict", response_model=BatchPredictResponse,
          summary="Predi√ß√£o em lote",
          description="‚Ä¢ O que √©: Processa m√∫ltiplos candidatos de uma vez.\n"
                      "‚Ä¢ Quando usar: Importa√ß√£o em pipelines em massa.\n"
                      "‚Ä¢ Que dor resolve: Efici√™ncia em lotes e integra√ß√µes.")
def batch_predict(req: BatchPredictRequest):
    df_enc = pd.get_dummies(pd.DataFrame([i.dict() for i in req.inputs]))
    aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro em lote: {e}")
    results = [PredictProbaResponse(prediction=int(p >= THRESHOLD), probability=float(p))
               for p in probs]
    return {"results": results}

@app.post("/explain", response_model=ExplainResponse,
          summary="Explica√ß√£o de decis√£o via SHAP",
          description="‚Ä¢ O que √©: Contribui√ß√£o de cada feature para o resultado.\n"
                      "‚Ä¢ Quando usar: Auditoria interna e feedback.\n"
                      "‚Ä¢ Que dor resolve: Transpar√™ncia local do modelo.")
def explain(req: PredictRequest):
    df_enc = pd.get_dummies(pd.DataFrame([req.dict()]))
    aligned = df_enc.reindex(columns=feature_names, fill_value=0)
    try:
        probs = modelo.predict_proba(aligned)[:, 1]
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Erro na predi√ß√£o: {e}")
    pred = int(probs[0] >= THRESHOLD)
    shap_vals = explainer.shap_values(aligned)[1][0]
    explanation = {feat: float(val) for feat, val in zip(feature_names, shap_vals)}
    return {"prediction": pred, "probability": float(probs[0]), "explanation": explanation}

@app.post("/compare", response_model=CompareResponse,
          summary="Comparar dois candidatos",
          description="‚Ä¢ O que √©: Compara predi√ß√µes, scores e SHAP delta.\n"
                      "‚Ä¢ Quando usar: Decis√£o entre dois perfis.\n"
                      "‚Ä¢ Que dor resolve: Aux√≠lio em tie-breaker de sele√ß√£o.")
def compare(req: CompareRequest):
    def run(r):
        enc = pd.get_dummies(pd.DataFrame([r.dict()]))
        aligned = enc.reindex(columns=feature_names, fill_value=0)
        prob = modelo.predict_proba(aligned)[:, 1][0]
        pred = int(prob >= THRESHOLD)
        shap_v = explainer.shap_values(aligned)[1][0]
        return pred, prob, dict(zip(feature_names, shap_v))
    a_pred, a_prob, a_shap = run(req.cand_a)
    b_pred, b_prob, b_shap = run(req.cand_b)
    delta = {f: b_shap[f] - a_shap[f] for f in feature_names}
    return {"a": {"prediction": a_pred, "probability": a_prob},
            "b": {"prediction": b_pred, "probability": b_prob},
            "delta": delta}

@app.post("/threshold", summary="Atualizar threshold de decis√£o",
          description="‚Ä¢ O que √©: Modifica corte sem redeploy.\n"
                      "‚Ä¢ Quando usar: Testes A/B ou ajustes r√°pidos.\n"
                      "‚Ä¢ Que dor resolve: Flexibilidade operacional.")
def set_threshold(req: ThresholdRequest):
    global THRESHOLD
    THRESHOLD = req.threshold
    return {"threshold": THRESHOLD}

@app.post("/feedback", summary="Registrar feedback",
          description="‚Ä¢ O que √©: Grava predi√ß√£o vs resultado real.\n"
                      "‚Ä¢ Quando usar: Logging cont√≠nuo de outcomes.\n"
                      "‚Ä¢ Que dor resolve: Monitoramento e melhoria do modelo.")
def feedback(fb: FeedbackRequest):
    record = fb.dict()
    log_path = os.path.join(os.path.dirname(PATH_MODEL), "feedback_log.jsonl")
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    with open(log_path, "a", encoding="utf-8") as f:
        f.write(json.dumps(record, ensure_ascii=False) + "\n")
    return {"status": "ok"}

@app.post("/historical_data", summary="Upload de dados hist√≥ricos",
          description="‚Ä¢ O que √©: Recebe CSV de entrevistas antigas.\n"
                      "‚Ä¢ Quando usar: Importa√ß√£o de massa para re-treino.\n"
                      "‚Ä¢ Que dor resolve: Centraliza e padroniza seu hist√≥rico.")
async def upload_historical(file: UploadFile = File(...)):
    os.makedirs("data", exist_ok=True)
    path = os.path.join("data", "historical_data.csv")
    with open(path, "wb") as f:
        f.write(await file.read())
    return {"status": "saved", "path": path}
